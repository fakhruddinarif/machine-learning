{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56745765",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880c7408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 05:07:19.597559: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-26 05:07:19.653980: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-26 05:07:19.887282: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-26 05:07:19.887362: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-26 05:07:19.889026: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-26 05:07:20.034582: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-26 05:07:20.037448: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-26 05:07:21.513008: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e305b098bb72b",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T22:32:54.926963Z",
     "start_time": "2024-10-23T22:32:54.915297Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: {'000021': 0, '000093': 1, '000099': 2, '000171': 3, '000278': 4, '000329': 5, '000375': 6, '000384': 7, '000397': 8, '000411': 9, '000454': 10, '000465': 11, '000536': 12, '000582': 13, '000650': 14, '000665': 15, '000672': 16, '000797': 17, '001005': 18, '001123': 19, '001149': 20, '001181': 21, '001268': 22, '001308': 23, '001333': 24, '001372': 25, '001521': 26, '001633': 27, '001652': 28, '001678': 29, '001696': 30, '002034': 31, '002035': 32, '002224': 33, '002250': 34, '002304': 35, '002350': 36, '002497': 37, '002761': 38, '002799': 39, '002825': 40, '002878': 41, '002949': 42, '002995': 43, '003084': 44, '003148': 45, '003189': 46, '003207': 47, '003249': 48, '003300': 49, '003356': 50, '003372': 51, '003446': 52, '003538': 53, '003563': 54, '003692': 55, '003719': 56, '003733': 57, '003861': 58, '003966': 59, '004039': 60, '004233': 61, '004284': 62, '004418': 63, '004540': 64, '004692': 65, '004891': 66, '004933': 67, '004961': 68, '005184': 69, '005233': 70, '005270': 71, '005290': 72, '005302': 73, '005363': 74, '005407': 75, '005479': 76, '005504': 77, '005591': 78, '005614': 79, '005618': 80, '005630': 81, '005662': 82, '005685': 83, '005691': 84, '005692': 85, '005790': 86, '005795': 87, '005799': 88, '005913': 89, '005934': 90, '005946': 91, '005964': 92, '006028': 93, '006035': 94, '006106': 95, '006214': 96, '006280': 97, '006322': 98, '006332': 99, '006337': 100, '006365': 101, '006468': 102, '006487': 103, '006491': 104, '006538': 105, '006555': 106, '006598': 107, '006628': 108, '006629': 109, '006664': 110, '006678': 111, '006692': 112, '006729': 113, '006737': 114, '006872': 115, '006874': 116, '006879': 117, '006903': 118, '007023': 119, '007150': 120, '007229': 121, '007261': 122, '007308': 123, '007329': 124, '007348': 125, '007405': 126, '007418': 127, '007424': 128, '007454': 129, '007482': 130, '007509': 131, '007579': 132, '007596': 133, '007604': 134, '007686': 135, '007757': 136, '007761': 137, '007843': 138, '007902': 139, '007924': 140, '007932': 141, '007953': 142, '008259': 143, '008278': 144, '008288': 145, '008292': 146, '008345': 147, '008368': 148, '008380': 149, '008421': 150, '008458': 151, '008536': 152, '008608': 153, '008620': 154, '008648': 155, '008711': 156, '008734': 157, '008750': 158, '008763': 159, '008815': 160, '008851': 161, '008858': 162, '008943': 163, '008977': 164, '009053': 165, '009059': 166, '009103': 167, '009139': 168, '009178': 169, '009249': 170, '009255': 171, '009280': 172, '009293': 173, '009364': 174, '009370': 175, '009446': 176, '009458': 177, '009491': 178, '009508': 179, '009530': 180, '009540': 181, '009640': 182, '009667': 183, '009717': 184, '009809': 185, '010054': 186, '010131': 187, '010137': 188, '010211': 189, '010227': 190, '010233': 191, '010261': 192, '010269': 193, '010357': 194, '010362': 195, '010392': 196, '010395': 197, '010500': 198, '010550': 199}\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 35s 142ms/step - loss: 5.0149 - accuracy: 0.0600\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 31s 130ms/step - loss: 4.5463 - accuracy: 0.1150\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 30s 127ms/step - loss: 4.1872 - accuracy: 0.1556\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 30s 125ms/step - loss: 3.8291 - accuracy: 0.2081\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 30s 125ms/step - loss: 3.5491 - accuracy: 0.2369\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 30s 127ms/step - loss: 3.2979 - accuracy: 0.2668\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 30s 128ms/step - loss: 3.0873 - accuracy: 0.2934\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 30s 127ms/step - loss: 2.9151 - accuracy: 0.3263\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 30s 126ms/step - loss: 2.7529 - accuracy: 0.3449\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 31s 131ms/step - loss: 2.5829 - accuracy: 0.3764\n",
      "60/60 [==============================] - 2s 26ms/step - loss: 3.6425 - accuracy: 0.2706\n",
      "Accuracy: 27.06%\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(folder_name, img_size = (112, 112)):\n",
    "    images, labels = [], []\n",
    "    folder_path = 'datasets/casia-webface/casia-webface/' + folder_name\n",
    "    \n",
    "    if os.path.exists(folder_path):\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img = cv.imread(os.path.join(folder_path, img_name))\n",
    "            if img is not None:\n",
    "                img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "                img = cv.resize(img, img_size)\n",
    "                images.append(img)\n",
    "                labels.append(folder_name)\n",
    "    else:\n",
    "        print(f'Folder {folder_name} contains a corrupted image: {img_name}')\n",
    "            \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def load_dataset(dataset_path, num_labels = 100, img_size = (112, 112)):\n",
    "    images, labels = [], []\n",
    "    \n",
    "    folder_names = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]\n",
    "\n",
    "    for folder_name in folder_names[:num_labels]:\n",
    "        imgs, lbls = load_images_from_folder(folder_name, img_size)\n",
    "        images.extend(imgs)\n",
    "        labels.extend(lbls)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Path to the dataset\n",
    "DATASET_PATH = 'datasets/casia-webface/casia-webface/'\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_dataset(DATASET_PATH, num_labels = 200)\n",
    "\n",
    "# Encode the labels\n",
    "unique_labels = np.unique(y)\n",
    "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "y_encoded = np.array([label_map[label] for label in y])\n",
    "y_categorical = tf.keras.utils.to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Normalize the images\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (112, 112, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(len(unique_labels), activation = 'softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size = 32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
